{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rU_AzGIgUAvv"
   },
   "source": [
    "![Spark Logo](http://spark-mooc.github.io/web-assets/images/ta_Spark-logo-small.png)  ![Python Logo](http://spark-mooc.github.io/web-assets/images/python-logo-master-v3-TM-flattened_small.png)\n",
    "# PEC2: Noviembre 2023\n",
    "\n",
    "# Contando palabras: Construye una aplicación que cuente palabras de forma eficiente\n",
    "\n",
    "Este laboratorio usara las tecnologías descritas en los materiales del curso sobre Spark para desarrollar una aplicación de conteo de palabras. \n",
    "\n",
    "Con el uso masivo de Internet y las redes sociales, el volumen de texto no estructurado esta creciendo dramáticamente, y Spark es una gran herramienta para analizar este tipo de datos. En esta PEC, vamos a escribir Código para encontrar las palabras mas comunes en un texto generado en latin, el ya conocido [Lorem Ipsum](https://www.lipsum.com/).\n",
    "\n",
    "\n",
    "Lo más interesante de la forma de trabajar en esta práctica es que podría escalarse para, por ejemplo, encontrar las palabras más comunes en Wikipedia.\n",
    "\n",
    "## Durante esta PEC vamos a cubrir:\n",
    "\n",
    "* *Parte 1:* Creación de un RDD y un pair RDD - **1.5 PUNTOS**\n",
    "* *Parte 2:* Contar palabras usando un pair RDD - **2.5 PUNTOS**\n",
    "* *Parte 3:* Encontrar las palabras individuales y su frecuencia de aparición media - **1 PUNTO**\n",
    "* *Parte 4:* Aplicar las funcionalidades desarrolladas a un archivo de texto* - **3 PUNTOS**\n",
    "* *Parte 5:* Calcular algunos estadísticos* - **2 PUNTOS**\n",
    "\n",
    "\n",
    "> Como referencia a todos los detalles de los métodos que se usan en esta práctica usar:\n",
    "> * [API Python de Spark](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD)\n",
    "\n",
    "## Formato de entrega:\n",
    "\n",
    "Para realizar la entrega, debéis subir los dos notebooks al apartado de evaluación, con el siguiente nombre:\n",
    "\n",
    "* usuarioUOC_22.519_PEC1_WordCount_ES.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tOlGjKpGUAvy"
   },
   "source": [
    "## Parte 1: Creacion de un RDD y un pair RDDs\n",
    "\n",
    "En esta sección, exploraremos como crear RRDs usando `parallelize` y como aplicar pair RDDs al problema del conteo de palabras.\n",
    "\n",
    "### (0) Configuración del entorno python + spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "F8iqGOuBUAvy"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "import random\n",
    "sc = pyspark.SparkContext(master=\"local[1]\", appName=\"PAC1_emadariagal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ir5gsMAUAvz"
   },
   "source": [
    "### (1a) Creación de un RDD\n",
    "Empecemos generando un RDD a partir de una lista de Python y el método `sc.parallelize`. Luego mostraremos por pantalla el tipo de la variable generada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "b9kkxkNeUAvz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordsList = ['cat', 'elephant', 'rat', 'rat', 'cat']\n",
    "wordsRDD = sc.parallelize(wordsList, 4)\n",
    "# Print out the type of wordsRDD\n",
    "type(wordsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0-cdh6.2.0\n",
      "3.5\n",
      "local[1]\n",
      "4\n",
      "[['cat'], ['elephant'], ['rat'], ['rat', 'cat']]\n"
     ]
    }
   ],
   "source": [
    "# Inspeccionar SparkContent\n",
    "print(sc.version) # Recuperar SparkContent Version\n",
    "print(sc.pythonVer) # Recuperar Python Version\n",
    "print(sc.master) # URL del clúster o del modo de ejecución local utilizado para crear el SparkContent.\n",
    "print(wordsRDD.getNumPartitions()) # Numero de particiones en el RDD wordsRDD.\n",
    "print(wordsRDD.glom().collect())# Visualizar contenido de cada particion de un RDD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNoKG_7-UAvz"
   },
   "source": [
    "### (1b) Crear el plural de las palabras y testear\n",
    "\n",
    "Vamos a utilizar una transformación `map()` para incorporar la letra 's' a cada uno de los strings almacenados en el RDD que acabamos de crear. Vamos a definir una función de Python que devuelva una palabra, que se le ha pasado como parámetro, incorporando una \"s\" al final de la misma. Reemplazar el texto `<FILL IN>` con la solución propuesta. después de haber definido correctamente la función `makePlural`, ejecutar la segunda celda que contiene un assert de test. Si la solución es correcta, se imprimira `1 test passed`.\n",
    "\n",
    "Esta será la forma habitual de trabajar en las PECs. Los ejercicios contendrán una explicación de lo que se espera, seguido de una celda de Código con uno o mas `<FILL IN>`. Las celdas que necesiten ser modificadas contendrán el texto `# TODO: Replace <FILL IN> with appropriate code` en la primera línea.\n",
    "\n",
    "Una vez se hayan sustituido todos los `<FILL IN>` por el Código Python adecuado, ejecutar la celda, y posteriormente ejecutar la celda siguiente de test para comprobar que la solución es la esperada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "Kr-4bemUUAvz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cats'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# definición funcion makePlural()\n",
    "def makePlural(word):\n",
    "    \"\"\"Adds an 's' to `word`.\n",
    "\n",
    "    Note:\n",
    "        This is a simple function that only adds an 's'.  \n",
    "\n",
    "    Args:\n",
    "        word (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: A string with 's' added to it.\n",
    "    \"\"\"\n",
    "    #return word +'s'\n",
    "    return word +'s'\n",
    "\n",
    "makePlural('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "DBqFmkj-UAv0"
   },
   "outputs": [],
   "source": [
    "# TEST Pluralize and test (1b)\n",
    "assert makePlural('rat') == 'rats', 'incorrect result: makePlural does not add an s' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JggznEUpUAv0"
   },
   "source": [
    "### (1c) Aplicar `makePlural` a nuestro RDD\n",
    "\n",
    "Ahora es el momento de aplicar nuestra función `makePlural()` a todos los elementos del RDD usando una transformación [map()](https://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.map). Posteriormente ejecutar la acción [collect()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.collect) para obtener el RDD transformado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "AvO0iQcCUAv0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cats', 'elephants', 'rats', 'rats', 'cats']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicar la función makePlural() a todos los elementos del RDD usando una transformación map().\n",
    "pluralRDD = wordsRDD.map(lambda x: makePlural(x))\n",
    "# .collect() devuelve todos los elementos del conjunto de datos RDD como un array.\n",
    "pluralRDD.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "oXbLJ4JXUAv0"
   },
   "outputs": [],
   "source": [
    "# TEST Apply makePlural to the base RDD(1c)\n",
    "assert pluralRDD.collect() == ['cats', 'elephants', 'rats', 'rats', 'cats'], 'incorrect values for pluralRDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "stnxOD-RUAv0"
   },
   "source": [
    "### (1d) Ejecutar una funcion `lambda` en un `map`\n",
    "\n",
    "Vamos a crear el mismo RDD usando una `lambda` function en lugar de una función con nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "w3RdGvskUAv0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cats', 'elephants', 'rats', 'rats', 'cats']\n"
     ]
    }
   ],
   "source": [
    "# Usando una transformación map conjuntamente con una función lambda aplicamos directamente el plural a cada elemento del RDD sin necesidad de usar la funcion makePlural().\n",
    "pluralLambdaRDD = wordsRDD.map(lambda x: x +'s')\n",
    "print(pluralLambdaRDD.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "Tg_TyFp4UAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Pass a lambda function to map (1d)\n",
    "assert pluralLambdaRDD.collect() == ['cats', 'elephants', 'rats', 'rats', 'cats'], 'incorrect values for pluralLambdaRDD (1d)'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G4duNGhDUAv1"
   },
   "source": [
    "### (1e) Numero de caracteres de cada una de las palabras\n",
    "\n",
    "Ahora vamos a usar un `map()` y una función lambda `lambda` para obtener el número de caracteres de cada palabra. Usaremos `collect` para guardar este resultado directamente en una variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "79i88VmBUAv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 9, 4, 4, 4]\n"
     ]
    }
   ],
   "source": [
    "# Obtener el número de caracteres de cada palabra del RDD\n",
    "pluralLengths = (pluralRDD.map(lambda x: len(x)).collect())\n",
    "print(pluralLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "AUfvQl6hUAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Length of each word (1e)\n",
    "assert pluralLengths == [4, 9, 4, 4, 4], 'incorrect values for pluralLengths'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nygi0_YgUAv1"
   },
   "source": [
    "### (1f) Pair RDDs\n",
    "\n",
    "El siguiente paso para completar nuestro programa de conteo de palabras en crear un nuevo tipo de RDD, llamado pair RDD. Un pair RDD es un RDD donde cada elemento es un tupla del estilo `(k, v)` donde `k` es la clave y `v` es su valor correspondiente. En este ejemplo, crearemos una pair RDD consistente en tuplas con el formato `('<word>', 1)` para cada elemento de nuestro RDD básico.\n",
    "\n",
    "Podemos crear nuestro pair RDD usando una transformación `map()` con una `lambda()` function que cree un nuevo RDD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "tfdCajY2UAv1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)]\n"
     ]
    }
   ],
   "source": [
    "# Crear pair RDD consistente en tuplas con el formato ('<word>', 1) para cada elemento de nuestro RDD básico.\n",
    "wordPairs = wordsRDD.map(lambda w : (w, 1))\n",
    "print(wordPairs.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "wS8XcRTnUAv1"
   },
   "outputs": [],
   "source": [
    "# TEST Pair RDDs (1f)\n",
    "assert wordPairs.collect() == [('cat', 1), ('elephant', 1), ('rat', 1), ('rat', 1), ('cat', 1)], 'incorrect value for wordPairs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S0LQd9pOUAv1"
   },
   "source": [
    "## Parte 2: Contar palabras usando un pair RDD\n",
    "\n",
    "Ahora, contaremos el número de veces que una palabra en particular aparece en el RDD. Esta operación se puede realizar de una infinidad de maneras, pero algunas serán mucho menos eficientes que otras.\n",
    "\n",
    "Un solución muy sencilla seria usar `collect()` sobre todos los elementos devolverlos al driver y allí contarlos. Mientras esta forma de trabajar podría funcionar con textos relativamente cortos, nosotros lo que queremos es poder trabajar con textos de cualquier longitud. Adicionalmente, ejecutar todo el cálculo en el driver es mucho más lento que ejecutarlo en paralelo en los workers. Por estos motivos, en esta práctica usaremos operaciones paralelizables.\n",
    "\n",
    "\n",
    "### (2a) Usando `groupByKey()`\n",
    "Una primera solución a nuestro problema, luego veremos que hay otras mucho más eficientes, se podría basar en la transformación [groupByKey()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.groupByKey). Como su nombre indica, la transformación `groupByKey()` agrupa todos los elementos de un RDD que compartan la misma clave en una única lista dentro de una de las particiones.\n",
    "\n",
    "Esta operación plantea dos problemas:\n",
    "  + Esta operación necesita mover todos los valores dentro de la partición adecuada. Esto satura la red. \n",
    "  + Las listas generadas pueden llegar a ser muy grandes llegando incluso a saturar la memoria de alguno de los trabajadores\n",
    "  \n",
    "Utiliza `groupByKey()` para generar un pair RDD del tipo `('word', iterator)`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "0RWmdQFLUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: [1, 1]\n",
      "elephant: [1]\n",
      "rat: [1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar groupByKey() para generar un pair RDD del tipo ('word', iterator).\n",
    "# Note that groupByKey requires no parameters\n",
    "wordsGrouped = wordPairs.groupByKey()\n",
    "for key, value in wordsGrouped.collect():\n",
    "    print('{0}: {1}'.format(key, list(value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Rs1VITEcUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST groupByKey() approach (2a)\n",
    "assert sorted(wordsGrouped.mapValues(lambda x: list(x)).collect()) == [('cat', [1, 1]), ('elephant', [1]), ('rat', [1, 1])], 'incorrect value for wordsGrouped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ao3HOCnUAv2"
   },
   "source": [
    "### (2b) Utiliza `groupByKey()` para obtener los conteos\n",
    "\n",
    "Usando la transformación `groupByKey()` crea un RDD que contenga 2 elementos, donde cada uno de ellos sea un par palabra (clave) iterador de Python (valor).\n",
    "\n",
    "Luego suma todos los valores de iterador usando una transformación `map()`. El resultado debe ser un pair RDD que contenga las parejas (word, count).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "Wl9NDpfaUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Suma de todos los valores de iterador usando la transformacion map() y aplicando la funcion lambda para obtener la estructura (word, count).\n",
    "wordCountsGrouped = wordsGrouped.map(lambda x: (x[0], sum(x[1])))\n",
    "print(wordCountsGrouped.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "Y-gYf8eDUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST Use groupByKey() to obtain the counts (2b)\n",
    "assert sorted(wordCountsGrouped.collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCountsGrouped'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9R6uGj_XUAv2"
   },
   "source": [
    "### (2c) Conteo usando `reduceByKey`\n",
    "\n",
    "Una mejor solución es comenzar desde un pair RDD y luego usar la transformación [reduceByKey()](http://spark.apache.org/docs/2.4.0/api/python/pyspark.html#pyspark.RDD.reduceByKey) para crear un nuevo pair RDD. La transformación `reduceByKey()` agrupa todas las parejas que comparten la misma clave. Posteriormente aplica la funcion que se le pasa por parámetro agrupando los valores de dos en dos. Este proceso se repite iterativamente hasta que obtenemos un único valor agregado para cada una de las claves del pair RDD. `reduceByKey()` opera aplicando la función primero dentro de cada una de las particiones de forma independiente, y posteriormente únicamente comparte los valores agregados entre particiones diferentes, permitiéndole escalar de forma eficiente ya que no tiene necesidad de desplazar por la red una gran cantidad de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "IagY-OxbUAv2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Usar la transformación reduceByKey() para crear un nuevo pair RDD  agrupando todas las parejas que comparten la misma clave , posteriormente aplica la funcion que se le pasa por parámetro.\n",
    "# Note that reduceByKey takes in a function that accepts two values and returns a single value\n",
    "wordCounts = wordPairs.reduceByKey(lambda x,y : x + y )\n",
    "print (wordCounts.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "8OC9pZ3VUAv2"
   },
   "outputs": [],
   "source": [
    "# TEST Counting using reduceByKey (2c)\n",
    "assert sorted(wordCounts.collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCounts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bul8z1FxUAv3"
   },
   "source": [
    "### (2d) Ahora todo junto\n",
    "\n",
    "La versión mas compleja del Código ejecuta primero un `map()` sobre el pair RDD, la transformación `reduceByKey()`, y finalmente la acción `collect()` en una única línea de Código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "id": "NZus2tT1UAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# Pipeline de los pasos en una línea de código.\n",
    "wordCountsCollected = (wordsRDD\n",
    "                       .map(lambda w : (w, 1))\n",
    "                       .reduceByKey(lambda x,y : x + y)\n",
    "                       .collect())\n",
    "print(wordCountsCollected)\n",
    "print(type(wordCountsCollected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "QJIImGKDUAv3"
   },
   "outputs": [],
   "source": [
    "# TEST All together (2d)\n",
    "assert sorted(wordCountsCollected)==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect value for wordCountsCollected'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y51nNytZUAv3"
   },
   "source": [
    "## Parte 3: Encontrar las palabras individuales y su frecuencia de aparición media\n",
    "\n",
    "### (3a) Palabras únicas\n",
    "\n",
    "Calcular el número de palabras únicas en `wordsRDD`. Puedes utilizar otros RDDs que hayas creado en esta práctica si te resulta más sencillo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "AZOfny2PUAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del número de palabras únicas en wordsRDD.\n",
    "# wordsRDD = [['cat'], ['elephant'], ['rat'], ['rat', 'cat']]\n",
    "uniqueWords = len(wordsRDD\n",
    "               .map(lambda w : (w, 1))\n",
    "               .reduceByKey(lambda x,y : x + y)\n",
    "               .collect())\n",
    "print(uniqueWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "EqAQ8HQ-UAv3"
   },
   "outputs": [],
   "source": [
    "# TEST Unique words (3a)\n",
    "assert uniqueWords== 3, 'incorrect count of uniqueWords'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3zLHxu4VUAv3"
   },
   "source": [
    "### (3b) Calcular la media usando `reduce()`\n",
    "\n",
    "Encuentra la frecuencia media de aparición de palabras en `wordCounts`.\n",
    "\n",
    "Utiliza la acción `reduce()` para sumar los conteos en `wordCounts` y entonces divide por el número de palabras únicas. Para realizar esto primero aplica un `map()` al pair RDD `wordCounts`, que está formado por tuplas con el formato (key, value), para convertirlo en un RDD de valores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.rdd.PipelinedRDD'>\n",
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "print(type(wordCounts))\n",
    "print(wordCounts.take(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "USu_rtacUAv3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "1.67\n"
     ]
    }
   ],
   "source": [
    "# Para calcular la media se obtiene la suma de los valores asociados a cada una de las claves, y se divide por el número de palabras únicas calculadas en el paso anterior.\n",
    "from operator import add\n",
    "totalCount = (wordCounts\n",
    "              .map(lambda x: x[1])\n",
    "              .reduce(lambda x, y: x + y))\n",
    "\n",
    "average = totalCount / float(uniqueWords)\n",
    "print(totalCount)\n",
    "print(round(average, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "3lEUGjUzUAv3"
   },
   "outputs": [],
   "source": [
    "# TEST Mean using reduce (3b)\n",
    "assert round(average, 2)==1.67, 'incorrect value of average'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkXpIsAXUAv4"
   },
   "source": [
    "## Parte 4: Aplicar las funcionalidades desarrolladas a un archivo de texto\n",
    "\n",
    "Para esto hemos de construir una función `wordCount`, capaz de trabajar con datos del mundo real que suelen presentan problemas como el uso de mayúsculas o minúsculas, puntuación, acentos, etc. Posteriormente, cargar los datos de nuestra fuente de datos y finalmente, calcular el conteo de palabras sobre los datos procesados.\n",
    "\n",
    "### (4a) función `wordCount`\n",
    "\n",
    "Primero, define una función para el conteo de palabras. deberías reusar las técnicas que has visto en los apartados anteriores de esta práctica. Dicha función, ha de tomar un RDD que contenga una lista de palabras, y devolver un pair RDD que contenga todas las palabras con sus correspondientes conteos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "Soh4Co_BUAv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('cat', 2), ('elephant', 1), ('rat', 2)]\n"
     ]
    }
   ],
   "source": [
    "def wordCount(wordListRDD):\n",
    "    \"\"\"Creates a pair RDD with word counts from an RDD of words.\n",
    "\n",
    "    Args:\n",
    "        wordListRDD (RDD of str): An RDD consisting of words.\n",
    "\n",
    "    Returns:\n",
    "        RDD of (str, int): An RDD consisting of (word, count) tuples.\n",
    "    \"\"\"\n",
    "    return wordListRDD.map(lambda w : (w, 1)).reduceByKey(lambda x,y : x + y)\n",
    "                           \n",
    "print(wordCount(wordsRDD).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "SkG-Ni6jUAv4"
   },
   "outputs": [],
   "source": [
    "# TEST wordCount function (4a)\n",
    "assert sorted(wordCount(wordsRDD).collect())==[('cat', 2), ('elephant', 1), ('rat', 2)],'incorrect definition for wordCount function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tPyU-FY2UAv4"
   },
   "source": [
    "### (4b) mayúsculas y puntuación\n",
    "\n",
    "Los ficheros del mundo real son mucho más complejos que los que hemos estado usando en esta PAC. Algunos de los problemas que son necesarios de solucionar son:\n",
    "  + Las palabras deben de contarse independientemente de si están en mayúscula o minúscula (por ejemplo, Spark y spark deberían contarse como la misma palabra).\n",
    "  + Todos los signos de puntuación han de eliminarse.\n",
    "  + Cualquier espacio al principio o al final de la palabra ha de eliminarse.\n",
    "  \n",
    "Define la función `removePunctuation` que convierta todo el texto a minúsculas, elimine los signos de puntuación, y elimine los espacios al principio y fin de cada palabra. Usa el módulo de Python [re](https://docs.python.org/2/library/re.html) para eliminar cualquier carácter que no sea una letra, un numero o un espacio.\n",
    "\n",
    "Sino estas familiarizado con las expresiones regulares deberías revisar [este tutorial](https://developers.google.com/edu/python/regular-expressions). Alternativamente, [esta web](https://regex101.com/#python) es de gran ayuda para debugar tus expresiones regulares.\n",
    "\n",
    "**Hints**\n",
    "\n",
    "1. Usa la función [re.sub()](https://docs.python.org/2.7/library/re.html#re.sub).\n",
    "2. Para nuestros propósitos, \"puntuación\" significa \"no alfabético, numérico, o espacio.\" La expresión regular que define estos caracteres es: `[^A-Za-z\\s\\d]`\n",
    "3. No usar `\\W`, ya que retendrá los guiones bajos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "id": "W1CTTYCjUAv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi you\n",
      "no underscore\n",
      "remove punctuation then spaces\n"
     ]
    }
   ],
   "source": [
    "# re.sub() se reemplace cada carácter  distinto al patron [^A-Za-z\\s\\d], es decir, elementos de puntuación por cadena vacia ''.\n",
    "# .lower() devuelve una cadena donde todos los caracteres están en minúsculas.\n",
    "# .strip() elimina los espacios en blanco iniciales y finales.\n",
    "import re\n",
    "def removePunctuation(text):\n",
    "    \"\"\"Removes punctuation, changes to lower case, and strips leading and trailing spaces.\n",
    "\n",
    "    Note:\n",
    "        Only whitespace, letters, and numbers should be retained.  Other characters should should be\n",
    "        eliminated (e.g. it's becomes its).  Leading and trailing spaces should be removed after\n",
    "        punctuation is removed.\n",
    "\n",
    "    Args:\n",
    "        text (str): A string.\n",
    "\n",
    "    Returns:\n",
    "        str: The cleaned up string.\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^A-Za-z\\s\\d]', '', text).lower().strip()\n",
    "    \n",
    "print(removePunctuation('Hi, you!'))\n",
    "print(removePunctuation(' No under_score!'))\n",
    "print(removePunctuation(' *      Remove punctuation then spaces  * '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "id": "gBUH5cXDUAv4"
   },
   "outputs": [],
   "source": [
    "# TEST Capitalization and punctuation (4b)\n",
    "assert removePunctuation(\" The Elephant's 4 cats. \") == 'the elephants 4 cats', 'incorrect definition for removePunctuation function'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s2uFF4D7UAv4"
   },
   "source": [
    "### (4c) Cargar un fichero de texto\n",
    "\n",
    "Para la siguiente parte, usaremos el texto ya mencionado Lorem Ipsum generado para la práctica. Para convertir un fichero de texto en un RDD, usaremos el método `SparkContext.textFile()`. También usaremos la función que acabamos de crear `removePunctuation()` dentro de una transformación `map()` para eliminar todos los caracteres no alfabéticos, numéricos o espacios. Dado que el fichero es bastante grande, usaremos `take(15)`, de forma que tan solo imprimiremos por pantalla las 15 primeras líneas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "id": "wOKwKY0LUAv4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aut minima deleniti et autem minus illo esse dolores eligendi corrupti dolore minima nostrum eos nobis nam nihil aspernatur nam ut quae sint laborum ut dolores error possimus aperiam consequatur',\n",
       " 'pariatur sed quo non itaque qui pariatur saepe ad quis consequatur nihil iste molestias et eos ut expedita vel reiciendis dolorem enim doloribus quam architecto aperiam',\n",
       " 'sed repudiandae pariatur similique est aut sequi animi in aperiam enim ipsa enim dolorem inventore aut quo odio in consequatur et',\n",
       " 'aspernatur ad esse et aliquid itaque dolores rerum quia commodi explicabo non magnam nostrum consectetur non sint eum nulla et aut quis doloribus itaque nulla molestiae quis est est quo facilis incidunt a ipsa in itaque sed aut nobis facere dignissimos atque unde cum ea vero',\n",
       " 'tenetur vel quod voluptatum laudantium dolores neque aut est modi qui aperiam itaque aperiam quae ratione doloremque aut delectus quas qui',\n",
       " 'qui placeat vel ipsam praesentium sint recusandae dicta minus praesentium omnis sequi a sed veritatis porro ab et officia esse commodi pariatur sequi cumque',\n",
       " 'mollitia facilis amet deleniti quia laborum commodi et molestias maxime quia dignissimos inventore neque libero deleniti ad quo corrupti numquam quis accusantium',\n",
       " 'architecto harum sunt et enim nisi commodi et id reprehenderit illum molestias illo facilis fuga eum illum quasi fugit qui',\n",
       " 'modi voluptatem quia et saepe inventore sed quo ea debitis explicabo vel perferendis commodi exercitationem sequi eum dolor cupiditate ab molestiae nemo ullam neque hic ipsa cupiditate dolor molestiae neque nam nobis nihil mollitia unde',\n",
       " 'voluptates quod in ipsum dicta fuga voluptatibus sint consequatur quod optio molestias nostrum repellendus consequatur aliquam fugiat provident omnis minus est quisquam exercitationem eum voluptas fugit quae eveniet perspiciatis assumenda maxime']"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tan solo ejecuta este codigo\n",
    "import os.path\n",
    "\n",
    "fileName = os.path.join('/aula_22.419/data/', 'LoremIpsum.txt')\n",
    "loremRDD = sc.textFile(fileName, 8).map(removePunctuation).filter(lambda x: len(x)>0)\n",
    "loremRDD.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mib6R2D3UAv4"
   },
   "source": [
    "\n",
    "### (4d) Extraer las palabras de las líneas\n",
    "\n",
    "Antes de poder usar la función `wordcount()`, hemos de solucionar dos problemas con el formato del RDD:\n",
    "  + El primer problema es que necesitamos dividir cada línea por sus espacios. ** Esto lo solucionaremos en el apartado (4d). **\n",
    "  + El segundo problema es que necesitamos filtrar las líneas completamente vacías. ** Esto lo solucionaremos en el apartado (4e). **\n",
    "\n",
    "Para aplicar una transformación que divida cada elemento del RDD por sus espacios, hemos de aplicar la función incorporada en los strings de Python [split()](https://docs.python.org/2/library/string.html#string.split). Cuidado que a primera vista puede parecer que la función necesaria es una transformación `map()`, pero si piensas un poco mas sobre el resultado de la función `split()` te darás cuenta que esta no es la opción correcta.\n",
    "\n",
    "> Nota:\n",
    "> * No uséis la implementación estándar del `split()`, debéis pasar un valor de separación. Por ejemplo, para dividir `line` por comas, usa `line.split(',')`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "id": "h3xOMu-CUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['voluptatum', 'voluptatum', 'voluptatum', 'voluptatum', 'voluptatum']\n",
      "29249699\n"
     ]
    }
   ],
   "source": [
    "# flatMap() Devuelve un nuevo RDD aplicando primero una función (lambda y a su vez, esta nos permite aplicar la funcion split(' ')) y continuación aplanar los resultados.\n",
    "loremWordsRDD = loremRDD.flatMap(lambda x: x.split(' '))\n",
    "loremWordsCount = loremWordsRDD.count()\n",
    "print(loremWordsRDD.top(5))\n",
    "print(loremWordsCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "9pGO_0vXUAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Words from lines (4d)\n",
    "# This test allows for leading spaces to be removed either before or after\n",
    "# punctuation is removed.\n",
    "assert loremWordsCount == 29249699, 'incorrect value for loremWordsCount'\n",
    "assert loremWordsRDD.top(5)==[u'voluptatum', u'voluptatum', u'voluptatum', u'voluptatum', u'voluptatum'], 'incorrect value for loremWordsRDD'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_sje3BOUAv5"
   },
   "source": [
    "### (4e) Calcula palabras distintas\n",
    "\n",
    "El siguiente paso es contar cuantas palabras distintas contiene nuestro texto. Puedes usar las transformaciones map() y reduceByKey() ya utilizadas anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "id": "_r9BSj_TUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tempora', 'sapiente', 'vitae', 'nisi', 'quidem', 'consectetur', 'perferendis', 'debitis']\n",
      "182\n"
     ]
    }
   ],
   "source": [
    "# La función .map(lambda w: (w, 1)) se utiliza para mapear cada palabra w en un par clave-valor (w, 1).  es decir, se asigna el valor 1 a cada palabra.\n",
    "# La función .reduceByKey(lambda x, y: x + y) se utiliza para realizar una reducción por clave, es decir, va a ir sumando aquellos valores asociados a claves comunes.\n",
    "distintWordsMapRDD = loremWordsRDD.map(lambda w: (w, 1)).reduceByKey(lambda x, y: x + y)\n",
    "\n",
    "# .keys() se utiliza para obtener las claves de un RDD o un DataFrame.\n",
    "# la función .distinct() se utiliza para eliminar los elementos duplicados de un RDD o un dataframes \n",
    "# Seleccionar claves unicas o lo que es lo mismo sin duplicados.\n",
    "distintWordsRDD=distintWordsMapRDD.keys().distinct()\n",
    "\n",
    "# Mostrar las 8 primeras claves del RDD\n",
    "print(distintWordsRDD.take(8))  \n",
    "# Contar el total de claves\n",
    "print(distintWordsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "id": "HrvMvo80UAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Remove empty elements (4e)\n",
    "assert distintWordsRDD.count()== 182, 'incorrect value for shakeWordCount'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZETOrsrLUAv5"
   },
   "source": [
    "### (4f) Cuenta las palabras\n",
    "\n",
    "Ahora que tenemos un RDD que contiene solo palabras. El siguiente paso es aplicar la función `wordCount()` para producir una lista con los conteos de palabras. Podemos ver las 15 más comunes usando la acción `takeOrdered()`; sin embargo, como los elementos del RRD son pares, necesitamos una función especial que ordene los pares de la forma correcta.\n",
    "\n",
    "Usad las funciones  `wordCount()` y `takeOrdered()` para obtener las 15 palabras más comunes junto con sus conteos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "id": "LPECIEqwUAv5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('et', 1291567), ('aut', 705322), ('ut', 704966), ('qui', 704703), ('est', 587782), ('voluptatem', 469634), ('quia', 469401), ('rerum', 353054), ('sed', 352873), ('omnis', 352653), ('consequatur', 352436), ('sit', 352396), ('non', 351959), ('voluptas', 351127), ('dolorem', 235822)]\n"
     ]
    }
   ],
   "source": [
    "# La función .takeOrdered(num, key=None) permite obtener los N elementos de un RDD ordenados en orden ascendente o  descentente según lo especificado en el parametro Key Opcional.\n",
    "# key = lambda x: -x[1] permite ordendar por el seundo elemento de la tupla y con el - invertir el orden , en este caso a descendente (de mayor a menor)\n",
    "top15WordsAndCounts = wordCount(loremWordsRDD).takeOrdered(15, key = lambda x: -x[1])\n",
    "print(top15WordsAndCounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "Q8lQntqLUAv5"
   },
   "outputs": [],
   "source": [
    "# TEST Count the words (4f)\n",
    "assert top15WordsAndCounts== [('et', 1291567), ('aut', 705322), \n",
    "                              ('ut', 704966), ('qui', 704703), \n",
    "                              ('est', 587782), ('voluptatem', 469634), \n",
    "                              ('quia', 469401), ('rerum', 353054), ('sed', 352873),\n",
    "                              ('omnis', 352653), ('consequatur', 352436), \n",
    "                              ('sit', 352396), ('non', 351959), ('voluptas', 351127), \n",
    "                              ('dolorem', 235822)],'incorrect value for top15WordsAndCounts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlZfu470UAv5"
   },
   "source": [
    "## Parte 5: Calcular algunos estadísticos\n",
    "\n",
    "Usando las mismas técnicas que has aplicado en los ejercicios anteriores responde a las siguientes preguntas:\n",
    "\n",
    "\n",
    "### (5a) De todas las palabras que tienen más de 6 letras ¿cuántas tienen exactamente una 'e' y una 'a'?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "recuento_palabras = wordCount(loremWordsRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tempora', 117602), ('sapiente', 118045)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuento_palabras.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_a_e(word):\n",
    "    num_a = word.count('a') \n",
    "    num_e = word.count('e')\n",
    "    \n",
    "    if num_a == 1 and num_e == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(count_a_e('tempora'))\n",
    "print(count_a_e('necessitatibus'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tempora', 7),\n",
       " ('consequatur', 11),\n",
       " ('voluptatem', 10),\n",
       " ('ratione', 7),\n",
       " ('voluptate', 9),\n",
       " ('veritatis', 9),\n",
       " ('voluptates', 10),\n",
       " ('molestias', 9),\n",
       " ('cupiditate', 10),\n",
       " ('maiores', 7),\n",
       " ('explicabo', 9),\n",
       " ('architecto', 10),\n",
       " ('perspiciatis', 12)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuento_palabras.map(lambda x: (x[0], len(x[0]))).filter(lambda x : x[1] > 6).filter(lambda x : count_a_e(x[0])).take(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAjhaRHxUAv5"
   },
   "source": [
    "### (5b) ¿Cuál es la longitud media de todas las palabras diferentes que comienzan con 'c'?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCount = (wordCounts\n",
    "              .map(lambda x: x[1])\n",
    "              .reduce(lambda x, y: x + y))\n",
    "\n",
    "average = totalCount / float(uniqueWords)\n",
    "print(totalCount)\n",
    "print(round(average, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comienzan_por_c(word):\n",
    "    if word[0] == 'c':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(comienzan_por_c('consequatur'))\n",
    "print(comienzan_por_c('explicabo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 11, 12, 8, 6, 5, 8, 3, 10, 7]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuento_palabras.filter(lambda x: comienzan_por_c(x[0])).map(lambda x: (x[0], len(x[0]))).map(lambda x: x[1]).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[11, 11, 12, 8, 6, 5, 8, 3, 10, 7]\n"
     ]
    }
   ],
   "source": [
    "unique_words = recuento_palabras.filter(lambda x: comienzan_por_c(x[0])).map(lambda x: (x[0], len(x[0]))).map(lambda x: x[1]).collect()\n",
    "print(type(unique_words))\n",
    "print(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "MErPqSuhUAv6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# Listado de valores que representan la longitud de cada una de las palabra que comienzan por c.\n",
    "totalCount = recuento_palabras.filter(lambda x: comienzan_por_c(x[0])).map(lambda x: (x[0], len(x[0]))).map(lambda x: x[1]).reduce(lambda x, y: x + y)\n",
    "print(totalCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "8.1\n"
     ]
    }
   ],
   "source": [
    "average = totalCount /len(unique_words)\n",
    "print(totalCount)\n",
    "print(round(average, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9brp6E-gUAv6"
   },
   "source": [
    "### (5c) ¿Cuántas palabras distintas tienen exactamente tres vocales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "id": "UeSLrBjpUAv6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recuento_palabras.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_vocals(word):\n",
    "    vocals = 'aeiou'\n",
    "    num_vocals = []\n",
    "    \n",
    "    for w in word:\n",
    "        if w in vocals:\n",
    "            num_vocals.append(w)\n",
    "    \n",
    "    if len(num_vocals) == 3:\n",
    "        return True\n",
    "    else:\n",
    "        return False                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['tempora',\n",
       " 'quidem',\n",
       " 'debitis',\n",
       " 'eius',\n",
       " 'earum',\n",
       " 'vitae',\n",
       " 'placeat',\n",
       " 'impedit',\n",
       " 'libero',\n",
       " 'autem',\n",
       " 'corrupti',\n",
       " 'voluptas',\n",
       " 'animi',\n",
       " 'iure',\n",
       " 'repellat']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(recuento_palabras.filter(lambda x: count_vocals(x[0])).count())\n",
    "recuento_palabras.filter(lambda x: count_vocals(x[0])).map(lambda w: w[0]).take(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(recuento_palabras.filter(lambda x: count_vocals(x[0])).collect())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "nygi0_YgUAv1",
    "-ao3HOCnUAv2",
    "9R6uGj_XUAv2",
    "bul8z1FxUAv3",
    "3zLHxu4VUAv3",
    "tPyU-FY2UAv4",
    "s2uFF4D7UAv4",
    "Mib6R2D3UAv4",
    "X_sje3BOUAv5",
    "ZETOrsrLUAv5",
    "gAjhaRHxUAv5",
    "9brp6E-gUAv6"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "Lab_1_WordCount",
  "notebookId": 1529163670453288
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
